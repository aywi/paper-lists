# Interpretability

Note: Papers with the paywall are followed by a `[PDF]` option, otherwise they are open access. Papers with the official code are followed by a `[Code]` option (incomplete).
Papers with the official blog are followed by a `[Blog]` option (incomplete).
Papers with the official slides are followed by a `[Slides]` option (incomplete).
Papers with the official talk are followed by a `[Talk]` option (incomplete).

URL: DOI (Open Access) >= Non-DOI (Open Access) >= Preprint > DOI (Paywalled) >= Non-DOI (Paywalled)
PDF: If URL <= DOI (Paywalled)

## General

- Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead [[URL](https://www.nature.com/articles/s42256-019-0048-x)]
- Shortcut learning in deep neural networks [[URL](https://www.nature.com/articles/s42256-020-00257-z)] [[Code](https://github.com/rgeirhos/shortcut-perspective)]
- AI for radiographic COVID-19 detection selects shortcuts over signal [[URL](https://www.nature.com/articles/s42256-021-00338-7)] [[Code](https://github.com/suinleelab/cxr_covid)]

## Case-based Models

- This looks like that: deep learning for interpretable image recognition [[URL](https://proceedings.neurips.cc/paper/2019/hash/adf7ee2dcf142b0e11888e72b43fcb75-Abstract.html)] [[Code](https://github.com/cfchen-duke/ProtoPNet)]
- A case-based interpretable deep learning model for classification of mass lesions in digital mammography [[URL](https://www.nature.com/articles/s42256-021-00423-x)] [[Code](https://github.com/alinajadebarnett/iaiabl)]
- XProtoNet: diagnosis in chest radiography with global and local explanations [[URL](https://arxiv.org/abs/2103.10663)]
- Neural prototype trees for interpretable fine-grained image recognition [[URL](https://openaccess.thecvf.com/content/CVPR2021/html/Nauta_Neural_Prototype_Trees_for_Interpretable_Fine-Grained_Image_Recognition_CVPR_2021_paper.html?ref=https://githubhelp.com)] [[Code](https://github.com/M-Nauta/ProtoTree)]

## Concept-based Models

- Towards robust interpretability with self-explaining neural networks [[URL](https://proceedings.neurips.cc/paper/2018/hash/3e9f0fc9b2f89e043bc6233994dfcf76-Abstract.html)] [[Code](https://github.com/dmelis/SENN)]
- Towards automatic concept-based explanations [[URL](https://proceedings.neurips.cc/paper/2019/hash/77d2afcb31f6493e350fca61764efb9a-Abstract.html)]
- Concept whitening for interpretable image recognition [[URL](https://www.nature.com/articles/s42256-020-00265-z)] [[Code](https://github.com/zhiCHEN96/ConceptWhitening)]
- Concept bottleneck models [[URL](https://proceedings.mlr.press/v119/koh20a.html)]
